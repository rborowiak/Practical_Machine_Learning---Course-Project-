---
output:
  pdf_document: default
  html_document: default
---
# Practical Machine Learning - Course Project: Prediction Lifting Exercise

RB,   
02.04.2021

```{r results='hide', message=FALSE, warning=FALSE}
library(data.table)
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(lattice)
library(caret)
library(knitr)
```

## I. Load training and test data set
The data for this project come from the Human Activity Recognition project:
*Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements. Proceedings of 21st Brazilian Symposium on Artificial Intelligence. Advances in Artificial Intelligence - SBIA 2012.*

*Excercise: Prediction of body postures and movements based on the measured accelerometers' sensor data* 

The data is already separated in training and testing data sets.

```{r}
train <- read.csv("train/pml-training.csv", sep = ",", dec = ".")
test  <- read.csv("test/pml-testing.csv", sep = ",", dec = ".")
```

## II. Explaratory Data Analyis and cleaning data
1. What is the structure of the data - number of variables and observations? 
2. Removing unnecessary variables/columns which mostly consists NAs.
```{r}
str(train)
```

Removing na-columns, columns consisting metadata (spurious correlations/order in the data) and columns with little variation which should be not useful for prediction as prediction should be based only on *measured sensor data*.

```{r}
train_clean <- train[,colMeans(is.na(train)) < .9] # filter out na-columns
train_clean <- train_clean[,-c(1:7)] # filter out  metadata - should be irrelevant for the prediction
train_clean <- train_clean[,-nearZeroVar(train_clean)] # filter out variables with near zero variance
dim(train_clean)
```

## III. Model building and training: Random Forest
For this classification problem we will use the well known Random Forest model ("wisdom of the crowd") as it is expected to predict better than a simple decision tree model.

```{r}
set.seed(1234)
```

To accelerate computation use the parallel mode of the caret package:
```{r}
library(parallel)
library(doParallel)
```

```{r}
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
fitControl <- trainControl(method = "cv", number = 5, allowParallel = TRUE)
RandomForest <- train(classe ~., method = "rf", trControl = fitControl, data = train_clean)
## close cluster
stopCluster(cluster)
registerDoSEQ()
```

**Results**: Confusion matrix and estimated error rate of the random forest model using five-fold cross validation and 500 trees

```{r}
RandomForest$finalModel
```

## IV. Prediction of random forest on test data sets

To answer the quiz the trained random forest model is used to predict the 5 classes (A, B, C, D, and E) for the 20 test cases. Note the trained random forest model is tested with the test data sets which are similarly pre-processed as the training sets and without pre-processing yielding the same classification results.

```{r}
test_clean <- test[,colMeans(is.na(test)) < .9] # filter out na-columns
test_clean <- test_clean[,-c(1:7)] # filter out  metadata - should be irrelevant for the prediction
# test_clean <- test_clean[,-nearZeroVar(test_clean)] # filter out variables with near zero variance
dim(test_clean)
```

```{r}
prediction_clean <- predict(RandomForest, test_clean)
prediction       <- predict(RandomForest, test)
print(prediction_clean)
print(prediction)
```
